{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCk2Rx4cjlYF"
      },
      "source": [
        "# Synthetic Data Generation Using RAGAS - RAG Evaluation with LangSmith\n",
        "\n",
        "In the following notebook we'll explore a use-case for RAGAS' synthetic testset generation workflow!\n",
        "\n",
        "\n",
        "\n",
        "- ðŸ¤ BREAKOUT ROOM #1\n",
        "  1. Use RAGAS to Generate Synthetic Data\n",
        "\n",
        "- ðŸ¤ BREAKOUT ROOM #2\n",
        "  1. Load them into a LangSmith Dataset\n",
        "  2. Evaluate our RAG chain against the synthetic test data\n",
        "  3. Make changes to our pipeline\n",
        "  4. Evaluate the modified pipeline\n",
        "\n",
        "SDG is a critical piece of the puzzle, especially for early iteration! Without it, it would not be nearly as easy to get high quality early signal for our application's performance.\n",
        "\n",
        "Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bG2ta-B478G"
      },
      "source": [
        "# ðŸ¤ BREAKOUT ROOM #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VUI7vF_kbv9"
      },
      "source": [
        "## Task 1: Dependencies and API Keys\n",
        "\n",
        "We'll need to install a number of API keys and dependencies, since we'll be leveraging a number of great technologies for this pipeline!\n",
        "\n",
        "1. OpenAI's endpoints to handle the Synthetic Data Generation\n",
        "2. OpenAI's Endpoints for our RAG pipeline and LangSmith evaluation\n",
        "3. QDrant as our vectorstore\n",
        "4. LangSmith for our evaluation coordinator!\n",
        "\n",
        "Let's install and provide all the required information below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependencies and API Keys:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NLTK Import\n",
        "\n",
        "To prevent errors that may occur based on OS - we'll import NLTK and download the needed packages to ensure correct handling of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/ash/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/ash/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "# import getpass\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv('../.env')\n",
        "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll also want to set a project name to make things easier for ourselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenAI's API Key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating Synthetic Test Data\n",
        "\n",
        "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
        "\n",
        "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preparation\n",
        "\n",
        "We'll prepare our data - which should hopefull be familiar at this point since it's our Use-Case Data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "\n",
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Knowledge Graph Based Synthetic Generation\n",
        "\n",
        "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
        "\n",
        "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unrolled SDG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we're going to instantiate our Knowledge Graph.\n",
        "\n",
        "This graph will contain N number of nodes that have M number of relationships. These nodes and relationships (AKA \"edges\") will define our knowledge graph and be used later to construct relevant questions and responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 0, relationships: 0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import KnowledgeGraph\n",
        "\n",
        "kg = KnowledgeGraph()\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step we're going to take is to simply insert each of our full documents into the graph. This will provide a base that we can apply transformations to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 64, relationships: 0)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import Node, NodeType\n",
        "\n",
        "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
        "for doc in docs:\n",
        "    kg.nodes.append(\n",
        "        Node(\n",
        "            type=NodeType.DOCUMENT,\n",
        "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
        "        )\n",
        "    )\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we'll apply the *default* transformations to our knowledge graph. This will take the nodes currently on the graph and transform them based on a set of [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms).\n",
        "\n",
        "These default transformations are dependent on the corpus length, in our case:\n",
        "\n",
        "- Producing Summaries -> produces summaries of the documents\n",
        "- Extracting Headlines -> finding the overall headline for the document\n",
        "- Theme Extractor -> extracts broad themes about the documents\n",
        "\n",
        "It then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d661016a7f543e2b7b894241c6e3bf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/21 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e57d0088a7ff4230a048672a7e5cc888",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/64 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e505ed9d78647b7832d27eb2948b200",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/38 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary' already exists in node '14db16'. Skipping!\n",
            "Property 'summary' already exists in node '9be0ea'. Skipping!\n",
            "Property 'summary' already exists in node '3a8d1c'. Skipping!\n",
            "Property 'summary' already exists in node '651275'. Skipping!\n",
            "Property 'summary' already exists in node '6337e4'. Skipping!\n",
            "Property 'summary' already exists in node '62a640'. Skipping!\n",
            "Property 'summary' already exists in node '5b3559'. Skipping!\n",
            "Property 'summary' already exists in node '31fd56'. Skipping!\n",
            "Property 'summary' already exists in node 'cc9752'. Skipping!\n",
            "Property 'summary' already exists in node '6da9e1'. Skipping!\n",
            "Property 'summary' already exists in node 'e56c44'. Skipping!\n",
            "Property 'summary' already exists in node '9e1387'. Skipping!\n",
            "Property 'summary' already exists in node '7bdefc'. Skipping!\n",
            "Property 'summary' already exists in node 'f446db'. Skipping!\n",
            "Property 'summary' already exists in node '51b782'. Skipping!\n",
            "Property 'summary' already exists in node 'b232b0'. Skipping!\n",
            "Property 'summary' already exists in node 'ed1b60'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c9ae797940c4a21bfae3b6db514343f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9502819dddc54e5583a587a275aca28c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/48 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary_embedding' already exists in node '3a8d1c'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '62a640'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '14db16'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'cc9752'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'e56c44'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '9be0ea'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '7bdefc'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '6337e4'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '5b3559'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '6da9e1'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '651275'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'f446db'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '9e1387'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '31fd56'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '51b782'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'ed1b60'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'b232b0'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f11d9e23f34b4d739628e00b84ed6b27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 86, relationships: 711)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.transforms import default_transforms, apply_transforms\n",
        "\n",
        "transformer_llm = generator_llm\n",
        "embedding_model = generator_embeddings\n",
        "\n",
        "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
        "apply_transforms(kg, default_transforms)\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save and load our knowledge graphs as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 86, relationships: 711)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.save(\"usecase_data_kg.json\")\n",
        "usecase_data_kg = KnowledgeGraph.load(\"usecase_data_kg.json\")\n",
        "usecase_data_kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using our knowledge graph, we can construct a \"test set generator\" - which will allow us to create queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=usecase_data_kg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, we'd like to be able to define the kinds of queries we're generating - which is made simple by Ragas having pre-created a number of different \"QuerySynthesizer\"s.\n",
        "\n",
        "Each of these Synthetsizers is going to tackle a separate kind of query which will be generated from a scenario and a persona.\n",
        "\n",
        "In essence, Ragas will use an LLM to generate a persona of someone who would interact with the data - and then use a scenario to construct a question from that data and persona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
        "\n",
        "query_distribution = [\n",
        "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
        "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### â“ Question #1:\n",
        "\n",
        "What are the three types of query synthesizers doing? Describe each one in simple terms.\n",
        "\n",
        "- SingleHopSpecificQuerySynthesizer: Generates straightforward, fact-based questions that can be answered using a single piece of information from the knowledge graph.\n",
        "\n",
        "- MultiHopAbstractQuerySynthesizer: Creates more complex, open-ended questions that require connecting multiple pieces of information or reasoning across the knowledge graph.\n",
        "\n",
        "- MultiHopSpecificQuerySynthesizer: Produces detailed, multi-step questions that need information from several places in the knowledge graph to answer, but with a specific, concrete answer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can use our `TestSetGenerator` to generate our testset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0ae4deb21564342bc698e51353c31d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37a3e73ba4574d64b2c45d5cdde30924",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f83728656ac442639016d07de35cd403",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Whaat is ChatGPT and how is it used in the con...</td>\n",
              "      <td>[Introduction ChatGPT launched in November 202...</td>\n",
              "      <td>ChatGPT is based on a Large Language Model (LL...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When is June 2025?</td>\n",
              "      <td>[Table 1: ChatGPT daily message counts (millio...</td>\n",
              "      <td>The context mentions June 2025 as the date end...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SOC2 codes 11 what is it</td>\n",
              "      <td>[Variation by Occupation Figure 23 presents va...</td>\n",
              "      <td>Variation by Occupation Figure 23 presents var...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Management how does it relate to ChatGPT use?</td>\n",
              "      <td>[Conclusion This paper studies the rapid growt...</td>\n",
              "      <td>The context discusses how users in management ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How do the statistical analysis and regression...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nVariation by Occupation Figure 23 ...</td>\n",
              "      <td>The variation in ChatGPT usage by occupation, ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do large language models (LLMs) like ChatG...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
              "      <td>ChatGPT, based on large language models (LLMs)...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How do the changes in user behavior and prefer...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nMonth Non-Work (M) (%) Work (M) (%...</td>\n",
              "      <td>Between June 2024 and June 2025, total ChatGPT...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does the rapid growth of ChatGPT usage by ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>By July 2025, ChatGPT experienced a significan...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Whi is the dat in July 2025 that show how Chat...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The context indicates that by July 2025, ChatG...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Based on the rapid growth of ChatGPT usage in ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The context indicates that by July 2025, over ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Based on the data, how has ChatGPT usage in th...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The context indicates that in the US, ChatGPT ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   Whaat is ChatGPT and how is it used in the con...   \n",
              "1                                  When is June 2025?   \n",
              "2                            SOC2 codes 11 what is it   \n",
              "3       Management how does it relate to ChatGPT use?   \n",
              "4   How do the statistical analysis and regression...   \n",
              "5   How do large language models (LLMs) like ChatG...   \n",
              "6   How do the changes in user behavior and prefer...   \n",
              "7   How does the rapid growth of ChatGPT usage by ...   \n",
              "8   Whi is the dat in July 2025 that show how Chat...   \n",
              "9   Based on the rapid growth of ChatGPT usage in ...   \n",
              "10  Based on the data, how has ChatGPT usage in th...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Introduction ChatGPT launched in November 202...   \n",
              "1   [Table 1: ChatGPT daily message counts (millio...   \n",
              "2   [Variation by Occupation Figure 23 presents va...   \n",
              "3   [Conclusion This paper studies the rapid growt...   \n",
              "4   [<1-hop>\\n\\nVariation by Occupation Figure 23 ...   \n",
              "5   [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
              "6   [<1-hop>\\n\\nMonth Non-Work (M) (%) Work (M) (%...   \n",
              "7   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "8   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "9   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "10  [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   ChatGPT is based on a Large Language Model (LL...   \n",
              "1   The context mentions June 2025 as the date end...   \n",
              "2   Variation by Occupation Figure 23 presents var...   \n",
              "3   The context discusses how users in management ...   \n",
              "4   The variation in ChatGPT usage by occupation, ...   \n",
              "5   ChatGPT, based on large language models (LLMs)...   \n",
              "6   Between June 2024 and June 2025, total ChatGPT...   \n",
              "7   By July 2025, ChatGPT experienced a significan...   \n",
              "8   The context indicates that by July 2025, ChatG...   \n",
              "9   The context indicates that by July 2025, over ...   \n",
              "10  The context indicates that in the US, ChatGPT ...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_specific_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Abstracted SDG\n",
        "\n",
        "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
        "\n",
        "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51009cf5e055437088fcbfbb946a13e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/21 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "604898b5bc8643bf802b512dfd617aac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/64 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d53f80f05dc14c2c893811e415ab4a2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/38 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary' already exists in node '210995'. Skipping!\n",
            "Property 'summary' already exists in node 'e7e722'. Skipping!\n",
            "Property 'summary' already exists in node 'bcbc72'. Skipping!\n",
            "Property 'summary' already exists in node 'bc5391'. Skipping!\n",
            "Property 'summary' already exists in node '030d25'. Skipping!\n",
            "Property 'summary' already exists in node 'b22839'. Skipping!\n",
            "Property 'summary' already exists in node '813df6'. Skipping!\n",
            "Property 'summary' already exists in node '7948bd'. Skipping!\n",
            "Property 'summary' already exists in node 'c23bf3'. Skipping!\n",
            "Property 'summary' already exists in node 'f568b8'. Skipping!\n",
            "Property 'summary' already exists in node '8898b1'. Skipping!\n",
            "Property 'summary' already exists in node 'fc718d'. Skipping!\n",
            "Property 'summary' already exists in node '49a4cf'. Skipping!\n",
            "Property 'summary' already exists in node 'c92ea8'. Skipping!\n",
            "Property 'summary' already exists in node '38b28b'. Skipping!\n",
            "Property 'summary' already exists in node 'e6084d'. Skipping!\n",
            "Property 'summary' already exists in node 'bc5040'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e50e415c368147c98702d8b1b32dfd5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3e9aa299792426a95f9ba5f8537caaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/48 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary_embedding' already exists in node '49a4cf'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '210995'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'fc718d'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'c23bf3'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'c92ea8'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'e7e722'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '813df6'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'f568b8'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'bc5391'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '030d25'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'bcbc72'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'b22839'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '7948bd'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '8898b1'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '38b28b'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'e6084d'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'bc5040'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4115e1142f44337a26f33a61930a89b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bb521e1c24e4adf801fad3943752cc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99d80969850a41a9bf11adf736b9e775",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2051f794ef2f4190bf9173cacda1964e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Considering the significant milestone of ChatG...</td>\n",
              "      <td>[Introduction ChatGPT launched in November 202...</td>\n",
              "      <td>ChatGPT was launched in November 2022, and sin...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OpenAI how does it help in education and what ...</td>\n",
              "      <td>[Table 1: ChatGPT daily message counts (millio...</td>\n",
              "      <td>OpenAI is involved in understanding product us...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As an Educational Technology Coordinator lever...</td>\n",
              "      <td>[Variation by Occupation Figure 23 presents va...</td>\n",
              "      <td>Variation in ChatGPT usage by occupation shows...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is practical guidance in ChatGPT usage?</td>\n",
              "      <td>[Conclusion This paper studies the rapid growt...</td>\n",
              "      <td>Practical Guidance is one of the three most co...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hw many chatgpt msgs are for info and wrting v...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nTable 1: ChatGPT daily message cou...</td>\n",
              "      <td>The context indicates that nearly 80% of all C...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the trends in monthly message statistic...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nMonth Non-Work (M) (%) Work (M) (%...</td>\n",
              "      <td>The data shows that from June 2024 to June 202...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>how chatgpt message volume and classify activi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nTable 1: ChatGPT daily message cou...</td>\n",
              "      <td>Table 1 shows that daily message counts for Ch...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does the rapid growth of ChatGPT since 202...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The rapid growth of ChatGPT since its launch i...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Considering the rapid growth of ChatGPT, which...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>By July 2025, ChatGPT's weekly usage by more t...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does the rapid growth of ChatGPT since its...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>Since its launch in November 2022, ChatGPT exp...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Hw many messages did ChatGPT send weekly by Ju...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>By July 2025, ChatGPT was sending more than 18...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>how many messages 18 billion and 2.5 billion m...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The context shows that by July 2025, ChatGPT u...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   Considering the significant milestone of ChatG...   \n",
              "1   OpenAI how does it help in education and what ...   \n",
              "2   As an Educational Technology Coordinator lever...   \n",
              "3        What is practical guidance in ChatGPT usage?   \n",
              "4   Hw many chatgpt msgs are for info and wrting v...   \n",
              "5   How do the trends in monthly message statistic...   \n",
              "6   how chatgpt message volume and classify activi...   \n",
              "7   How does the rapid growth of ChatGPT since 202...   \n",
              "8   Considering the rapid growth of ChatGPT, which...   \n",
              "9   How does the rapid growth of ChatGPT since its...   \n",
              "10  Hw many messages did ChatGPT send weekly by Ju...   \n",
              "11  how many messages 18 billion and 2.5 billion m...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Introduction ChatGPT launched in November 202...   \n",
              "1   [Table 1: ChatGPT daily message counts (millio...   \n",
              "2   [Variation by Occupation Figure 23 presents va...   \n",
              "3   [Conclusion This paper studies the rapid growt...   \n",
              "4   [<1-hop>\\n\\nTable 1: ChatGPT daily message cou...   \n",
              "5   [<1-hop>\\n\\nMonth Non-Work (M) (%) Work (M) (%...   \n",
              "6   [<1-hop>\\n\\nTable 1: ChatGPT daily message cou...   \n",
              "7   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "8   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "9   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "10  [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "11  [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   ChatGPT was launched in November 2022, and sin...   \n",
              "1   OpenAI is involved in understanding product us...   \n",
              "2   Variation in ChatGPT usage by occupation shows...   \n",
              "3   Practical Guidance is one of the three most co...   \n",
              "4   The context indicates that nearly 80% of all C...   \n",
              "5   The data shows that from June 2024 to June 202...   \n",
              "6   Table 1 shows that daily message counts for Ch...   \n",
              "7   The rapid growth of ChatGPT since its launch i...   \n",
              "8   By July 2025, ChatGPT's weekly usage by more t...   \n",
              "9   Since its launch in November 2022, ChatGPT exp...   \n",
              "10  By July 2025, ChatGPT was sending more than 18...   \n",
              "11  The context shows that by July 2025, ChatGPT u...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vSRr2MXk0P_"
      },
      "source": [
        "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLDUsLJg43k7"
      },
      "source": [
        "# ðŸ¤ BREAKOUT ROOM #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SLtk1GtnyoY"
      },
      "source": [
        "## Task 4: LangSmith Dataset\n",
        "\n",
        "Now we can move on to creating a dataset for LangSmith!\n",
        "\n",
        "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
        "\n",
        "We'll name our Dataset to make it easy to work with later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TLgm6OjvYSsm"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = \"Use Case Synthetic Data - AIE8 v2\"\n",
        "\n",
        "langsmith_dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Synthetic Data for Use Cases\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64SmXMBnzXWm"
      },
      "source": [
        "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
        "\n",
        "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8nFQ6di_XnY7"
      },
      "outputs": [],
      "source": [
        "for data_row in dataset.to_pandas().iterrows():\n",
        "  client.create_example(\n",
        "      inputs={\n",
        "          \"question\": data_row[1][\"user_input\"]\n",
        "      },\n",
        "      outputs={\n",
        "          \"answer\": data_row[1][\"reference\"]\n",
        "      },\n",
        "      metadata={\n",
        "          \"context\": data_row[1][\"reference_contexts\"]\n",
        "      },\n",
        "      dataset_id=langsmith_dataset.id\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6EbQVyZq-2j"
      },
      "source": [
        "## Basic RAG Chain\n",
        "\n",
        "Time for some RAG!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4njbUAIsaYjB"
      },
      "outputs": [],
      "source": [
        "rag_documents = docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQorBy8H1AZR"
      },
      "source": [
        "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qWo3Ajaragv1"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "rag_documents = text_splitter.split_documents(rag_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kghuTb9R01oO"
      },
      "source": [
        "We'll create our vectorstore using OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UwfJCzP3aqKI"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpCLS-a01Ft2"
      },
      "source": [
        "As usual, we will power our RAG application with Qdrant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "58Ypj_NgbEsi"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents=rag_documents,\n",
        "    embedding=embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Use Case RAG\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SbKSjfSkbTYo"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxUOMaQX1K2N"
      },
      "source": [
        "To get the \"A\" in RAG, we'll provide a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1sLeY1oWbVqO"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and question, you must answer the question based only on context.\n",
        "\n",
        "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZnHDh4e1Ou5"
      },
      "source": [
        "As is usual: We'll be using `gpt-4.1-mini` for our RAG!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6nx-ue1XbciV"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmTL6-pc1ZGz"
      },
      "source": [
        "Finally, we can set-up our RAG LCEL chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TjWj0OLIbbFc"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | rag_prompt | llm | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WQ7bEweo4IIb",
        "outputId": "d161b269-f799-4920-d6ce-c202f6e783aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, people are using AI, particularly generative AI like ChatGPT, in many flexible ways both at work and outside of work. Key activities include:\\n\\n- Performing workplace tasks either by augmenting or automating human labor.\\n- Producing writing, software code, spreadsheets, and other digital products.\\n- Using AI as co-workers that produce output or as co-pilots that give advice and improve human problem-solving.\\n- Seeking information and advice, similar to how they use traditional web search engines.\\n- Engaging in self-expression activities like relationships, personal reflection, games, and role play (though these represent a smaller share of use).\\n- Therapy or companionship has been noted as a prevalent use case.\\n\\nOverall, AI is being used to enhance productivity, creativity, and decision-making across various economic and social activities.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke({\"question\" : \"What are people doing with AI these days?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9hBh5YPrdGJ"
      },
      "source": [
        "## LangSmith Evaluation Set-up\n",
        "\n",
        "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gfwPYdIkcvpF"
      },
      "outputs": [],
      "source": [
        "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b8pToKH2K28"
      },
      "source": [
        "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PXSG-_ajckp6"
      },
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": (\n",
        "                \"Is this submission helpful to the user,\"\n",
        "                \" taking into account the correct reference answer?\"\n",
        "            )\n",
        "        },\n",
        "        \"llm\" : eval_llm\n",
        "    },\n",
        "    prepare_data=lambda run, example: {\n",
        "        \"prediction\": run.outputs[\"output\"],\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "dopeness_evaluator = LangChainStringEvaluator(\n",
        "    \"criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"dopeness\": \"Is this response dope, lit, cool, or is it just a generic response?\",\n",
        "        },\n",
        "        \"llm\" : eval_llm\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0SQP_FoCetP"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #2:\n",
        "\n",
        "Highlight what each evaluator is evaluating.\n",
        "\n",
        "- `qa_evaluator`: Evaluates whether the model's answer is factually correct and matches the expected reference answer. The label `\"qa\"` refers to a built-in LangSmith evaluation type for question answering accuracy.\n",
        "\n",
        "- `labeled_helpfulness_evaluator`: Assesses how helpful the answer is to the user, taking into account the correct reference answer. The label `\"labeled_criteria\"` is used in LangSmith to specify custom evaluation criteria that are explicitly labeled, in this case, \"helpfulness\".\n",
        "\n",
        "- `dopeness_evaluator`: Judges if the response is unique, interesting, and \"dope\" (i.e., not generic or boring). The label `\"criteria\"` in LangSmith allows you to define custom evaluation criteria, here used for the \"dopeness\" metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R35sQMHVrnpl"
      },
      "source": [
        "## LangSmith Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "122b1bd1f0e9417a8dcb57d4eebe4d2e",
            "e0c233ad01604540a6c873f4a731982d",
            "e9a01115c75b499884f7e0ef32e9e599",
            "5faba4ad609448b2b49024add4ad3b8e",
            "ef25efa751304e4699910f1fbc14345f",
            "0b44cb0f8e34446c8dde668a75d3d8ad",
            "edaac6587b2d4bd5be52b89bb097f99f",
            "7cb241365f604419af454c1c28de197a",
            "9cf586576ff44dba86ba2eb389593c61",
            "849b5c95008541d49f1ceedf0a59ac60",
            "f3665a86662746c4ac7cb0796604781d"
          ]
        },
        "id": "t7t_Uz0tdumL",
        "outputId": "d684e218-294e-4dc3-c8de-a01d397f021c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'unique-love-79' at:\n",
            "https://smith.langchain.com/o/a58e59bf-7551-4351-b574-57c230dc2aa6/datasets/9ff69106-4780-4042-a51d-41486ff1415d/compare?selectedSessions=aba2a8f8-668c-4a1f-9e9c-646c15e32356\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6c9615797de4934b0756be0f7b21ae3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.answer</th>\n",
              "      <th>feedback.correctness</th>\n",
              "      <th>feedback.helpfulness</th>\n",
              "      <th>feedback.dopeness</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how many messages 18 billion and 2.5 billion m...</td>\n",
              "      <td>Based on the provided context:\\n\\n- The exact ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context shows that by July 2025, ChatGPT u...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.366211</td>\n",
              "      <td>7145eab0-21aa-4bdb-93a7-a69c7a1abc92</td>\n",
              "      <td>60bb1b3b-3cf9-4259-89fa-ac53b7f69171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hw many messages did ChatGPT send weekly by Ju...</td>\n",
              "      <td>By July 2025, ChatGPT users were collectively ...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, ChatGPT was sending more than 18...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.949315</td>\n",
              "      <td>9ab933b3-7159-4c16-877f-34ef9fd07bbf</td>\n",
              "      <td>bb0fff21-5aea-4141-bb94-67fdc7bb364f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the rapid growth of ChatGPT since its...</td>\n",
              "      <td>The rapid growth of ChatGPT since its launch i...</td>\n",
              "      <td>None</td>\n",
              "      <td>Since its launch in November 2022, ChatGPT exp...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.407433</td>\n",
              "      <td>3439e2bf-0b89-4698-b360-c8c41b36b60f</td>\n",
              "      <td>cfd47a42-aecf-42e5-a0ed-343fe12e7893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Considering the rapid growth of ChatGPT, which...</td>\n",
              "      <td>The extensive adoption of ChatGPTâ€”used weekly ...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, ChatGPT's weekly usage by more t...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.322455</td>\n",
              "      <td>28017ba6-25e3-4f41-a4b5-107a2f0be8bf</td>\n",
              "      <td>ab5ff3be-6b4e-43a1-9335-8715fdeddf35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does the rapid growth of ChatGPT since 202...</td>\n",
              "      <td>The rapid growth of ChatGPT since its launch i...</td>\n",
              "      <td>None</td>\n",
              "      <td>The rapid growth of ChatGPT since its launch i...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.312861</td>\n",
              "      <td>a3e96e4c-cc01-43a0-a342-cb5bf287dc71</td>\n",
              "      <td>679cd134-17bb-46f5-b512-551e61660e49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>how chatgpt message volume and classify activi...</td>\n",
              "      <td>Based on the provided context:\\n\\n- Writing is...</td>\n",
              "      <td>None</td>\n",
              "      <td>Table 1 shows that daily message counts for Ch...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9.426799</td>\n",
              "      <td>3b0ba9db-2649-462f-b5d5-c5c30ec4e723</td>\n",
              "      <td>71a38cd9-f93b-4ab9-b755-31e221b757c0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How do the trends in monthly message statistic...</td>\n",
              "      <td>Based on the provided context, trends in month...</td>\n",
              "      <td>None</td>\n",
              "      <td>The data shows that from June 2024 to June 202...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.846879</td>\n",
              "      <td>3fad9b01-cf8d-464b-b91b-ad45e59a6709</td>\n",
              "      <td>2a8d40b4-db3a-4747-8cf5-e892dd082a65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hw many chatgpt msgs are for info and wrting v...</td>\n",
              "      <td>Based on the provided context:\\n\\n- Only 4.2% ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context indicates that nearly 80% of all C...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9.380094</td>\n",
              "      <td>7d501354-9090-4404-8b51-1d96f61b9557</td>\n",
              "      <td>89d5a359-92c7-4411-935b-038148afcc6e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is practical guidance in ChatGPT usage?</td>\n",
              "      <td>Based on the provided context, Practical Guida...</td>\n",
              "      <td>None</td>\n",
              "      <td>Practical Guidance is one of the three most co...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.266928</td>\n",
              "      <td>e0812ccc-f5fa-4544-bbbf-a248128fdde9</td>\n",
              "      <td>25f28498-cf94-4367-a15a-c8712abf731d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>As an Educational Technology Coordinator lever...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>None</td>\n",
              "      <td>Variation in ChatGPT usage by occupation shows...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.720266</td>\n",
              "      <td>93d2d624-c564-4742-91bc-36cb6534efa5</td>\n",
              "      <td>3df82ca0-bdaa-4307-9b01-752893db0985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>OpenAI how does it help in education and what ...</td>\n",
              "      <td>Based on the provided context, OpenAI's ChatGP...</td>\n",
              "      <td>None</td>\n",
              "      <td>OpenAI is involved in understanding product us...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.230158</td>\n",
              "      <td>75ff172a-de48-48cd-b7f9-fb08cefe4251</td>\n",
              "      <td>d9e8eb09-46b3-49e0-a90c-e15caff2058c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Considering the significant milestone of ChatG...</td>\n",
              "      <td>Since its launch in November 2022, ChatGPT exp...</td>\n",
              "      <td>None</td>\n",
              "      <td>ChatGPT was launched in November 2022, and sin...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.915690</td>\n",
              "      <td>e70582c2-2f40-4145-a6e3-22c92a44da9d</td>\n",
              "      <td>c22d7201-1555-4d84-a33e-f1f99309049d</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<ExperimentResults unique-love-79>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(\n",
        "    rag_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "        labeled_helpfulness_evaluator,\n",
        "        dopeness_evaluator\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"default_chain_init\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq7fCVinrpI4"
      },
      "source": [
        "## Dope-ifying Our Application\n",
        "\n",
        "We'll be making a few changes to our RAG chain to increase its performance on our SDG evaluation test dataset!\n",
        "\n",
        "- Include a \"dope\" prompt augmentation\n",
        "- Use larger chunks\n",
        "- Improve the retriever model to: `text-embedding-3-large`\n",
        "\n",
        "Let's see how this changes our evaluation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "z56pXwyUgFUt"
      },
      "outputs": [],
      "source": [
        "DOPENESS_RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and question, you must answer the question based only on context.\n",
        "\n",
        "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
        "\n",
        "Make your answer rad, ensure high levels of dopeness. Do not be generic, or give generic responses.\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "dopeness_rag_prompt = ChatPromptTemplate.from_template(DOPENESS_RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rZLcTstJgfv5"
      },
      "outputs": [],
      "source": [
        "rag_documents = docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-LYsyirngj6n"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "rag_documents = text_splitter.split_documents(rag_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spldiPuTCzDO"
      },
      "source": [
        "#### â“Question #2:\n",
        "\n",
        "Why would modifying our chunk size modify the performance of our application?\n",
        "\n",
        "Modifying the chunk size changes how much context is included in each document chunk that is embedded and retrieved. \n",
        "If the chunks are too small, important information may be split across multiple chunks, making it less likely that the retriever will surface all relevant context for a given question. If the chunks are too large, they may include irrelevant information, which can confuse the model or dilute the relevance of the retrieved context. \n",
        "\n",
        "The optimal chunk size balances these trade-offs, ensuring that each chunk is large enough to contain meaningful context but not so large that it introduces noise, thereby improving retrieval accuracy and the quality of generated answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "b9MI2Bm2go1r"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBbjG6cKC8BQ"
      },
      "source": [
        "#### â“Question #3:\n",
        "\n",
        "Why would modifying our embedding model modify the performance of our application?\n",
        "\n",
        "Modifying the embedding model changes how well the RAG system can understand and retrieve relevant information. More advanced embedding models create better representations that capture more nuanced semantic relationships between words, phrases, and concepts. This allows them to encode context, meaning, and even subtle distinctions in language more effectively, resulting in embeddings that are more accurate and useful for retrieval tasks. As a result, the RAG system can match questions to relevant documents with higher precision, improving the quality of answers. In contrast, less advanced models may produce embeddings that miss important context or fail to distinguish between similar but distinct concepts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hVUY25FKgxXx"
      },
      "outputs": [],
      "source": [
        "vectorstore = Qdrant.from_documents(\n",
        "    documents=rag_documents,\n",
        "    embedding=embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Use Case RAG Docs\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Q4TOZNYIg2v1"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqYGFrnKDB91"
      },
      "source": [
        "Setting up our new and improved DOPE RAG CHAIN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HqnTqeXMhAdx"
      },
      "outputs": [],
      "source": [
        "dopeness_rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | dopeness_rag_prompt | llm | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21pTxoqJDI1Y"
      },
      "source": [
        "Let's test it on the same output that we saw before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OfZZ3MoN3fKv",
        "outputId": "d65722dd-92c2-4e4e-9cca-c42ee6f3f208"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Alright, buckle up because the way folks are stacking cash with AI is straight-up next-level wizardry. According to the juicy insights from the context, people arenâ€™t just using AI as a fancy tool to punch in tasksâ€”they're leveraging ChatGPT as a **decision-making sidekick and research advisor** in the workplace. Itâ€™s like having the smartest partner who boosts your brainâ€™s horsepower, especially in knowledge-dense gigs where every choice counts.\\n\\nSo instead of AI just clocking boring tasks, itâ€™s **amplifying worker output by supercharging the quality of their decisions**â€”making them sharper, faster, and maybe even a bit more legendary at what they do. This elevated decision support translates to better productivity and, bam, more money moves.\\n\\nPlus, the sheer value is colossal: Collis and Brynjolfsson (2025) drop this beast of a statâ€”US users would need a $98 monthly payout just to skip using AI, reflecting a mind-boggling **$97 billion per year surplus**. Thatâ€™s AI turning into a goldmine not by replacing jobs but by **helping humans crush their work smarter**.\\n\\nIn short: the money magic happens when AI gets into your corner as an advisor and research partner, elevating your work game rather than just automating the grunt work. Productivity and paychecks get a turbo boost through smarter decisions powered by generative AI.\\n\\n**Thatâ€™s how people are cashing in on AIâ€™s rad powersâ€”by turning it into the ultimate workplace wingman.** Mic drop.\""
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dopeness_rag_chain.invoke({\"question\" : \"How are people using AI to make money?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpj7v1inDLnQ"
      },
      "source": [
        "Finally, we can evaluate the new chain on the same test set!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "bf8dcc0895054529af356da401c513f6",
            "7dce19ac55264f2b88a0e4730e55867b",
            "2a0755d4476543feb4a64538e3e37213",
            "158212a630f04cbd884c937f2f60f5c8",
            "11c7f66acc1d45be9517d0addf49331e",
            "ddffd834e09940a4bd3874c3f39b4e21",
            "ef63c3b2d51e452da03cdae5d9b034be",
            "c20b539cd70b4ba99601ad1d69fd9cec",
            "a6d681eeafa44d18b933a4c5dec88382",
            "d1d54ccd56494c4d831f71b416a1f880",
            "530f696feefe499da08c6312047379b2"
          ]
        },
        "id": "Dx11S2b-hIM8",
        "outputId": "d3a3ea78-aa32-4bd2-8c2a-d0d0303695c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'scholarly-grain-54' at:\n",
            "https://smith.langchain.com/o/a58e59bf-7551-4351-b574-57c230dc2aa6/datasets/9ff69106-4780-4042-a51d-41486ff1415d/compare?selectedSessions=0041d008-6ea0-4982-aefe-d0ebf8e531ae\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1ebd90fc47e472b9b494c5f1b0fe76e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.answer</th>\n",
              "      <th>feedback.correctness</th>\n",
              "      <th>feedback.helpfulness</th>\n",
              "      <th>feedback.dopeness</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how many messages 18 billion and 2.5 billion m...</td>\n",
              "      <td>Yo, hereâ€™s the epic lowdown straight from the ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context shows that by July 2025, ChatGPT u...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.552142</td>\n",
              "      <td>7145eab0-21aa-4bdb-93a7-a69c7a1abc92</td>\n",
              "      <td>3cf5c481-2bb2-4ee2-935e-d2ddd6aa6165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hw many messages did ChatGPT send weekly by Ju...</td>\n",
              "      <td>Yo, check this out! By June 2025, ChatGPT was ...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, ChatGPT was sending more than 18...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.415600</td>\n",
              "      <td>9ab933b3-7159-4c16-877f-34ef9fd07bbf</td>\n",
              "      <td>269710c4-8038-4520-a9f0-28b0d3535c1d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the rapid growth of ChatGPT since its...</td>\n",
              "      <td>Yo, brace yourself for this mind-blowing ChatG...</td>\n",
              "      <td>None</td>\n",
              "      <td>Since its launch in November 2022, ChatGPT exp...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.153453</td>\n",
              "      <td>3439e2bf-0b89-4698-b360-c8c41b36b60f</td>\n",
              "      <td>57a4fe43-30d1-40bd-898d-b98134bb9d39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Considering the rapid growth of ChatGPT, which...</td>\n",
              "      <td>Yo, this massive surge to 700 million weekly u...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, ChatGPT's weekly usage by more t...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.072241</td>\n",
              "      <td>28017ba6-25e3-4f41-a4b5-107a2f0be8bf</td>\n",
              "      <td>6270b6c5-131e-4e09-b195-824d95d57070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does the rapid growth of ChatGPT since 202...</td>\n",
              "      <td>Oh, buckle upâ€”this answerâ€™s got some serious j...</td>\n",
              "      <td>None</td>\n",
              "      <td>The rapid growth of ChatGPT since its launch i...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.042744</td>\n",
              "      <td>a3e96e4c-cc01-43a0-a342-cb5bf287dc71</td>\n",
              "      <td>994d7652-7f6f-499a-b428-3c16b90c3fa8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>how chatgpt message volume and classify activi...</td>\n",
              "      <td>Alright, letâ€™s break down the beast of ChatGPT...</td>\n",
              "      <td>None</td>\n",
              "      <td>Table 1 shows that daily message counts for Ch...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8.039882</td>\n",
              "      <td>3b0ba9db-2649-462f-b5d5-c5c30ec4e723</td>\n",
              "      <td>c480d1d8-e1a3-4f42-8992-2dcd88084c14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How do the trends in monthly message statistic...</td>\n",
              "      <td>Alright, letâ€™s crank up the cool factor and di...</td>\n",
              "      <td>None</td>\n",
              "      <td>The data shows that from June 2024 to June 202...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.721420</td>\n",
              "      <td>3fad9b01-cf8d-464b-b91b-ad45e59a6709</td>\n",
              "      <td>01a71960-14f3-41a8-a546-4ca32cff77e4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hw many chatgpt msgs are for info and wrting v...</td>\n",
              "      <td>Alright, let's break down the vibe in this AI ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context indicates that nearly 80% of all C...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.714435</td>\n",
              "      <td>7d501354-9090-4404-8b51-1d96f61b9557</td>\n",
              "      <td>07ae5b5a-33a7-4766-b4e4-6a5fe0177363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is practical guidance in ChatGPT usage?</td>\n",
              "      <td>Alright, let's crank up the cool factor and br...</td>\n",
              "      <td>None</td>\n",
              "      <td>Practical Guidance is one of the three most co...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.688803</td>\n",
              "      <td>e0812ccc-f5fa-4544-bbbf-a248128fdde9</td>\n",
              "      <td>332c600e-38ea-4606-9729-fee6dea38daf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>As an Educational Technology Coordinator lever...</td>\n",
              "      <td>Alright, buckle up for some next-level AI insi...</td>\n",
              "      <td>None</td>\n",
              "      <td>Variation in ChatGPT usage by occupation shows...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.566596</td>\n",
              "      <td>93d2d624-c564-4742-91bc-36cb6534efa5</td>\n",
              "      <td>2ee510f1-6509-4d5b-b3d9-8b7d6792f7f8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>OpenAI how does it help in education and what ...</td>\n",
              "      <td>Yo, letâ€™s break down the rad ways OpenAI and C...</td>\n",
              "      <td>None</td>\n",
              "      <td>OpenAI is involved in understanding product us...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.426340</td>\n",
              "      <td>75ff172a-de48-48cd-b7f9-fb08cefe4251</td>\n",
              "      <td>5f6c0b07-2197-42b9-b7e8-dfe6f9a162bf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Considering the significant milestone of ChatG...</td>\n",
              "      <td>Oh, buckle up, because ChatGPTâ€™s rocket ride s...</td>\n",
              "      <td>None</td>\n",
              "      <td>ChatGPT was launched in November 2022, and sin...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.185326</td>\n",
              "      <td>e70582c2-2f40-4145-a6e3-22c92a44da9d</td>\n",
              "      <td>aafdd874-afb5-4644-8f87-662fdb2bf853</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<ExperimentResults scholarly-grain-54>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(\n",
        "    dopeness_rag_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "        labeled_helpfulness_evaluator,\n",
        "        dopeness_evaluator\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"dopeness_rag_chain\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C7migvlDPZT"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #3:\n",
        "\n",
        "Provide a screenshot of the difference between the two chains, and explain why you believe certain metrics changed in certain ways.\n",
        "\n",
        "CHAIN 1\n",
        "![Chain 1](chain1.png)\n",
        "\n",
        "CHAIN 2\n",
        "![Chain 2](chain2.png)\n",
        "\n",
        "Some differences between chain 1 and chain 2 are:\n",
        "- Chain 1 scored 0.8 correctness and 0.8 helpfulness vs chain 2 that scored 1.0 correctness and 0.9 helpfulness\n",
        "- All of Chain 1 responses scored \"no\" on \"dopeness\". All of chain 2 scored \"yes\" on \"dopeness\".\n",
        "- Average latency for chain 1 was 5.5 vs 6.3 for chain 2. Not a significant difference.\n",
        "- Chain 1 generated 43,553 tokens in total, costing a total of 0.0206 cents.\n",
        "- Chain 2 generated 26,723 tokens, costing a total of 0.0155 cents.\n",
        "- For chain 1, one of the incorrect responses was \"i don't know\". I think our eval could be improved to score this differently, since we prefer \"i don't know\" to a hallucinated answer. If the model was not powerful to answer the question, and made that clear, i think that should be scored differently than \"incorrect\" hallucinated answers.\n",
        "\n",
        "Well the biggest difference between the chains is the dopeness metric. Chain 2 scored higher than chain 1 because chain 2 was instructed in the prompt to return dope, non-generic answers, whereas nothing of that sort was mentioned in the prompt for chain 1.\n",
        "\n",
        "Another interesting difference is that chain 2 generated less tokens and cost less overall for this task, despite using a more expensive embedding model.\n",
        "\n",
        "The larger embedding model and larger chunks certainly helped chain 2 to achieve higher levels of correctness and helpfulness because it likely gained a better understanding of the meaning and intent in the reference text, and of the user's question. The larger embedding model generates more precise vector embeddings, that allow the question and the reference text to have cosine similarities that are more in line with reality. That sets the base for model to perform a more accurate search for an answer."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07ab3dc0790241bbb85a7f488a42ef8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7710c7377cbc4c30b55b28b4bc99e88f",
              "IPY_MODEL_41bdd49fab5f4826959d0d50663ff539",
              "IPY_MODEL_60168d85131d4afc99d55d61ab954ee6"
            ],
            "layout": "IPY_MODEL_9edf898aeeab40dda9b9475395776521"
          }
        },
        "095f680d37a3430fb82d223615662db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b44cb0f8e34446c8dde668a75d3d8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10df31709059484c99f102453d780473": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1160a44dc18e47b0890f70c40eaa7eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11c7f66acc1d45be9517d0addf49331e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122b1bd1f0e9417a8dcb57d4eebe4d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0c233ad01604540a6c873f4a731982d",
              "IPY_MODEL_e9a01115c75b499884f7e0ef32e9e599",
              "IPY_MODEL_5faba4ad609448b2b49024add4ad3b8e"
            ],
            "layout": "IPY_MODEL_ef25efa751304e4699910f1fbc14345f"
          }
        },
        "158212a630f04cbd884c937f2f60f5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1d54ccd56494c4d831f71b416a1f880",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_530f696feefe499da08c6312047379b2",
            "value": "â€‡20/?â€‡[01:43&lt;00:00,â€‡â€‡5.25s/it]"
          }
        },
        "23863bc37a8645029934b8c106622c51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2508d229935744cbb5fc340222e2d660": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a0755d4476543feb4a64538e3e37213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c20b539cd70b4ba99601ad1d69fd9cec",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6d681eeafa44d18b933a4c5dec88382",
            "value": 1
          }
        },
        "33f063017b7c4c7fa8cbafc89674350b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6864c81e2bcf459bbaf5acbb36bdfcbe",
              "IPY_MODEL_59d6e269eadf429a924f6f79bc8ba4ba",
              "IPY_MODEL_ca791fc471e34b9da2f9070fc1053c0f"
            ],
            "layout": "IPY_MODEL_8baf0ed3d0f743f294e07f2b5407e820"
          }
        },
        "3a8537e37fc14fd9b16ca0ceee4fede6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bdd49fab5f4826959d0d50663ff539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb8b2e3262c45248708a2082c366f0a",
            "max": 64,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_095f680d37a3430fb82d223615662db5",
            "value": 64
          }
        },
        "530f696feefe499da08c6312047379b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59d6e269eadf429a924f6f79bc8ba4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_890e0dd7fa524ceca1e805cb6253ee71",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61b52ff459214129b8f7e6d67b192b78",
            "value": 20
          }
        },
        "5ab5f08afa5841709aedb2f78a52a11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c2fda99d4204d85b1bf7ad354fd58d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5faba4ad609448b2b49024add4ad3b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849b5c95008541d49f1ceedf0a59ac60",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f3665a86662746c4ac7cb0796604781d",
            "value": "â€‡20/?â€‡[01:27&lt;00:00,â€‡â€‡6.45s/it]"
          }
        },
        "60168d85131d4afc99d55d61ab954ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8537e37fc14fd9b16ca0ceee4fede6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1160a44dc18e47b0890f70c40eaa7eb0",
            "value": "â€‡61/64â€‡[00:02&lt;00:00,â€‡23.36it/s]"
          }
        },
        "61b52ff459214129b8f7e6d67b192b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6864c81e2bcf459bbaf5acbb36bdfcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10df31709059484c99f102453d780473",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2508d229935744cbb5fc340222e2d660",
            "value": "Generating:â€‡100%"
          }
        },
        "6eb8b2e3262c45248708a2082c366f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7710c7377cbc4c30b55b28b4bc99e88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c2fda99d4204d85b1bf7ad354fd58d4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_93cd4d35c5fd41f5904ca1d52d1f52a8",
            "value": "embeddingâ€‡nodes:â€‡â€‡95%"
          }
        },
        "7cb241365f604419af454c1c28de197a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7dce19ac55264f2b88a0e4730e55867b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddffd834e09940a4bd3874c3f39b4e21",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ef63c3b2d51e452da03cdae5d9b034be",
            "value": ""
          }
        },
        "849b5c95008541d49f1ceedf0a59ac60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "890e0dd7fa524ceca1e805cb6253ee71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8baf0ed3d0f743f294e07f2b5407e820": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93cd4d35c5fd41f5904ca1d52d1f52a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cf586576ff44dba86ba2eb389593c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9edf898aeeab40dda9b9475395776521": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a6d681eeafa44d18b933a4c5dec88382": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf8dcc0895054529af356da401c513f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dce19ac55264f2b88a0e4730e55867b",
              "IPY_MODEL_2a0755d4476543feb4a64538e3e37213",
              "IPY_MODEL_158212a630f04cbd884c937f2f60f5c8"
            ],
            "layout": "IPY_MODEL_11c7f66acc1d45be9517d0addf49331e"
          }
        },
        "c20b539cd70b4ba99601ad1d69fd9cec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ca791fc471e34b9da2f9070fc1053c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23863bc37a8645029934b8c106622c51",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5ab5f08afa5841709aedb2f78a52a11c",
            "value": "â€‡20/20â€‡[00:52&lt;00:00,â€‡â€‡4.50s/it]"
          }
        },
        "d1d54ccd56494c4d831f71b416a1f880": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddffd834e09940a4bd3874c3f39b4e21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c233ad01604540a6c873f4a731982d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b44cb0f8e34446c8dde668a75d3d8ad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_edaac6587b2d4bd5be52b89bb097f99f",
            "value": ""
          }
        },
        "e9a01115c75b499884f7e0ef32e9e599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cb241365f604419af454c1c28de197a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cf586576ff44dba86ba2eb389593c61",
            "value": 1
          }
        },
        "edaac6587b2d4bd5be52b89bb097f99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef25efa751304e4699910f1fbc14345f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef63c3b2d51e452da03cdae5d9b034be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3665a86662746c4ac7cb0796604781d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
